nohup: ignoring input
I0830 18:22:20.251684 10575 finetune_net.cpp:25] Starting Optimization
I0830 18:22:20.251782 10575 solver.cpp:42] Creating training net.
I0830 18:22:20.252327 10575 net.cpp:76] Creating Layer data
I0830 18:22:20.252341 10575 net.cpp:112] data -> data
I0830 18:22:20.252351 10575 net.cpp:112] data -> label
I0830 18:22:20.252373 10575 data_layer.cpp:145] Opening leveldb hatch_markings_train_leveldb
I0830 18:22:20.331084 10575 data_layer.cpp:185] output data size: 128,3,227,227
I0830 18:22:20.331109 10575 data_layer.cpp:204] Loading mean file from../../data/hatch_markings/hatch_markings_mean.binaryproto
I0830 18:22:20.571933 10575 net.cpp:127] Top shape: 128 3 227 227 (19787136)
I0830 18:22:20.571964 10575 net.cpp:127] Top shape: 128 1 1 1 (128)
I0830 18:22:20.571971 10575 net.cpp:158] data does not need backward computation.
I0830 18:22:20.571985 10575 net.cpp:76] Creating Layer conv1
I0830 18:22:20.571990 10575 net.cpp:86] conv1 <- data
I0830 18:22:20.572005 10575 net.cpp:112] conv1 -> conv1
I0830 18:22:20.573458 10575 net.cpp:127] Top shape: 128 96 55 55 (37171200)
I0830 18:22:20.573472 10575 net.cpp:153] conv1 needs backward computation.
I0830 18:22:20.573479 10575 net.cpp:76] Creating Layer relu1
I0830 18:22:20.573484 10575 net.cpp:86] relu1 <- conv1
I0830 18:22:20.573490 10575 net.cpp:100] relu1 -> conv1 (in-place)
I0830 18:22:20.573498 10575 net.cpp:127] Top shape: 128 96 55 55 (37171200)
I0830 18:22:20.573501 10575 net.cpp:153] relu1 needs backward computation.
I0830 18:22:20.573508 10575 net.cpp:76] Creating Layer pool1
I0830 18:22:20.573511 10575 net.cpp:86] pool1 <- conv1
I0830 18:22:20.573516 10575 net.cpp:112] pool1 -> pool1
I0830 18:22:20.573528 10575 net.cpp:127] Top shape: 128 96 27 27 (8957952)
I0830 18:22:20.573537 10575 net.cpp:153] pool1 needs backward computation.
I0830 18:22:20.573550 10575 net.cpp:76] Creating Layer norm1
I0830 18:22:20.573559 10575 net.cpp:86] norm1 <- pool1
I0830 18:22:20.573567 10575 net.cpp:112] norm1 -> norm1
I0830 18:22:20.573668 10575 net.cpp:127] Top shape: 128 96 27 27 (8957952)
I0830 18:22:20.573680 10575 net.cpp:153] norm1 needs backward computation.
I0830 18:22:20.573693 10575 net.cpp:76] Creating Layer conv2
I0830 18:22:20.573703 10575 net.cpp:86] conv2 <- norm1
I0830 18:22:20.573711 10575 net.cpp:112] conv2 -> conv2
I0830 18:22:20.586124 10575 net.cpp:127] Top shape: 128 256 27 27 (23887872)
I0830 18:22:20.586153 10575 net.cpp:153] conv2 needs backward computation.
I0830 18:22:20.586165 10575 net.cpp:76] Creating Layer relu2
I0830 18:22:20.586174 10575 net.cpp:86] relu2 <- conv2
I0830 18:22:20.586185 10575 net.cpp:100] relu2 -> conv2 (in-place)
I0830 18:22:20.586199 10575 net.cpp:127] Top shape: 128 256 27 27 (23887872)
I0830 18:22:20.586206 10575 net.cpp:153] relu2 needs backward computation.
I0830 18:22:20.586216 10575 net.cpp:76] Creating Layer pool2
I0830 18:22:20.586225 10575 net.cpp:86] pool2 <- conv2
I0830 18:22:20.586235 10575 net.cpp:112] pool2 -> pool2
I0830 18:22:20.586246 10575 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0830 18:22:20.586256 10575 net.cpp:153] pool2 needs backward computation.
I0830 18:22:20.586269 10575 net.cpp:76] Creating Layer norm2
I0830 18:22:20.586277 10575 net.cpp:86] norm2 <- pool2
I0830 18:22:20.586287 10575 net.cpp:112] norm2 -> norm2
I0830 18:22:20.586298 10575 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0830 18:22:20.586308 10575 net.cpp:153] norm2 needs backward computation.
I0830 18:22:20.586319 10575 net.cpp:76] Creating Layer conv3
I0830 18:22:20.586328 10575 net.cpp:86] conv3 <- norm2
I0830 18:22:20.586336 10575 net.cpp:112] conv3 -> conv3
I0830 18:22:20.622491 10575 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0830 18:22:20.622520 10575 net.cpp:153] conv3 needs backward computation.
I0830 18:22:20.622532 10575 net.cpp:76] Creating Layer relu3
I0830 18:22:20.622541 10575 net.cpp:86] relu3 <- conv3
I0830 18:22:20.622552 10575 net.cpp:100] relu3 -> conv3 (in-place)
I0830 18:22:20.622561 10575 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0830 18:22:20.622567 10575 net.cpp:153] relu3 needs backward computation.
I0830 18:22:20.622580 10575 net.cpp:76] Creating Layer conv4
I0830 18:22:20.622587 10575 net.cpp:86] conv4 <- conv3
I0830 18:22:20.622596 10575 net.cpp:112] conv4 -> conv4
I0830 18:22:20.649762 10575 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0830 18:22:20.649791 10575 net.cpp:153] conv4 needs backward computation.
I0830 18:22:20.649803 10575 net.cpp:76] Creating Layer relu4
I0830 18:22:20.649812 10575 net.cpp:86] relu4 <- conv4
I0830 18:22:20.649823 10575 net.cpp:100] relu4 -> conv4 (in-place)
I0830 18:22:20.649832 10575 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0830 18:22:20.649839 10575 net.cpp:153] relu4 needs backward computation.
I0830 18:22:20.649850 10575 net.cpp:76] Creating Layer conv5
I0830 18:22:20.649858 10575 net.cpp:86] conv5 <- conv4
I0830 18:22:20.649865 10575 net.cpp:112] conv5 -> conv5
I0830 18:22:20.667979 10575 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0830 18:22:20.668006 10575 net.cpp:153] conv5 needs backward computation.
I0830 18:22:20.668018 10575 net.cpp:76] Creating Layer relu5
I0830 18:22:20.668027 10575 net.cpp:86] relu5 <- conv5
I0830 18:22:20.668040 10575 net.cpp:100] relu5 -> conv5 (in-place)
I0830 18:22:20.668048 10575 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0830 18:22:20.668056 10575 net.cpp:153] relu5 needs backward computation.
I0830 18:22:20.668066 10575 net.cpp:76] Creating Layer pool5
I0830 18:22:20.668073 10575 net.cpp:86] pool5 <- conv5
I0830 18:22:20.668081 10575 net.cpp:112] pool5 -> pool5
I0830 18:22:20.668092 10575 net.cpp:127] Top shape: 128 256 6 6 (1179648)
I0830 18:22:20.668100 10575 net.cpp:153] pool5 needs backward computation.
I0830 18:22:20.668115 10575 net.cpp:76] Creating Layer fc6
I0830 18:22:20.668123 10575 net.cpp:86] fc6 <- pool5
I0830 18:22:20.668133 10575 net.cpp:112] fc6 -> fc6
I0830 18:22:22.202533 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:22.202561 10575 net.cpp:153] fc6 needs backward computation.
I0830 18:22:22.202570 10575 net.cpp:76] Creating Layer relu6
I0830 18:22:22.202576 10575 net.cpp:86] relu6 <- fc6
I0830 18:22:22.202584 10575 net.cpp:100] relu6 -> fc6 (in-place)
I0830 18:22:22.202589 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:22.202594 10575 net.cpp:153] relu6 needs backward computation.
I0830 18:22:22.202600 10575 net.cpp:76] Creating Layer drop6
I0830 18:22:22.202604 10575 net.cpp:86] drop6 <- fc6
I0830 18:22:22.202608 10575 net.cpp:100] drop6 -> fc6 (in-place)
I0830 18:22:22.202620 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:22.202625 10575 net.cpp:153] drop6 needs backward computation.
I0830 18:22:22.202632 10575 net.cpp:76] Creating Layer fc7
I0830 18:22:22.202636 10575 net.cpp:86] fc7 <- fc6
I0830 18:22:22.202641 10575 net.cpp:112] fc7 -> fc7
I0830 18:22:22.884860 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:22.884887 10575 net.cpp:153] fc7 needs backward computation.
I0830 18:22:22.884896 10575 net.cpp:76] Creating Layer relu7
I0830 18:22:22.884902 10575 net.cpp:86] relu7 <- fc7
I0830 18:22:22.884908 10575 net.cpp:100] relu7 -> fc7 (in-place)
I0830 18:22:22.884914 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:22.884918 10575 net.cpp:153] relu7 needs backward computation.
I0830 18:22:22.884924 10575 net.cpp:76] Creating Layer drop7
I0830 18:22:22.884928 10575 net.cpp:86] drop7 <- fc7
I0830 18:22:22.884932 10575 net.cpp:100] drop7 -> fc7 (in-place)
I0830 18:22:22.884938 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:22.884943 10575 net.cpp:153] drop7 needs backward computation.
I0830 18:22:22.884948 10575 net.cpp:76] Creating Layer fc8_hatch
I0830 18:22:22.884951 10575 net.cpp:86] fc8_hatch <- fc7
I0830 18:22:22.884956 10575 net.cpp:112] fc8_hatch -> fc8_hatch
I0830 18:22:22.885306 10575 net.cpp:127] Top shape: 128 2 1 1 (256)
I0830 18:22:22.885315 10575 net.cpp:153] fc8_hatch needs backward computation.
I0830 18:22:22.885321 10575 net.cpp:76] Creating Layer loss
I0830 18:22:22.885326 10575 net.cpp:86] loss <- fc8_hatch
I0830 18:22:22.885331 10575 net.cpp:86] loss <- label
I0830 18:22:22.885345 10575 net.cpp:153] loss needs backward computation.
I0830 18:22:22.885375 10575 net.cpp:182] Collecting Learning Rate and Weight Decay.
I0830 18:22:22.885387 10575 net.cpp:175] Network initialization done.
I0830 18:22:22.885391 10575 net.cpp:176] Memory required for Data 536869888
I0830 18:22:22.885433 10575 solver.cpp:45] Creating testing net.
I0830 18:22:22.886060 10575 net.cpp:76] Creating Layer data
I0830 18:22:22.886072 10575 net.cpp:112] data -> data
I0830 18:22:22.886080 10575 net.cpp:112] data -> label
I0830 18:22:22.886088 10575 data_layer.cpp:145] Opening leveldb hatch_markings_val_leveldb
I0830 18:22:22.931174 10575 data_layer.cpp:185] output data size: 128,3,227,227
I0830 18:22:22.931192 10575 data_layer.cpp:204] Loading mean file from../../data/hatch_markings/hatch_markings_mean.binaryproto
I0830 18:22:22.972841 10575 net.cpp:127] Top shape: 128 3 227 227 (19787136)
I0830 18:22:22.972865 10575 net.cpp:127] Top shape: 128 1 1 1 (128)
I0830 18:22:22.972872 10575 net.cpp:158] data does not need backward computation.
I0830 18:22:22.972885 10575 net.cpp:76] Creating Layer conv1
I0830 18:22:22.972892 10575 net.cpp:86] conv1 <- data
I0830 18:22:22.972899 10575 net.cpp:112] conv1 -> conv1
I0830 18:22:22.974308 10575 net.cpp:127] Top shape: 128 96 55 55 (37171200)
I0830 18:22:22.974320 10575 net.cpp:153] conv1 needs backward computation.
I0830 18:22:22.974328 10575 net.cpp:76] Creating Layer relu1
I0830 18:22:22.974333 10575 net.cpp:86] relu1 <- conv1
I0830 18:22:22.974339 10575 net.cpp:100] relu1 -> conv1 (in-place)
I0830 18:22:22.974344 10575 net.cpp:127] Top shape: 128 96 55 55 (37171200)
I0830 18:22:22.974349 10575 net.cpp:153] relu1 needs backward computation.
I0830 18:22:22.974354 10575 net.cpp:76] Creating Layer pool1
I0830 18:22:22.974359 10575 net.cpp:86] pool1 <- conv1
I0830 18:22:22.974364 10575 net.cpp:112] pool1 -> pool1
I0830 18:22:22.974370 10575 net.cpp:127] Top shape: 128 96 27 27 (8957952)
I0830 18:22:22.974375 10575 net.cpp:153] pool1 needs backward computation.
I0830 18:22:22.974386 10575 net.cpp:76] Creating Layer norm1
I0830 18:22:22.974395 10575 net.cpp:86] norm1 <- pool1
I0830 18:22:22.974401 10575 net.cpp:112] norm1 -> norm1
I0830 18:22:22.974409 10575 net.cpp:127] Top shape: 128 96 27 27 (8957952)
I0830 18:22:22.974414 10575 net.cpp:153] norm1 needs backward computation.
I0830 18:22:22.974421 10575 net.cpp:76] Creating Layer conv2
I0830 18:22:22.974424 10575 net.cpp:86] conv2 <- norm1
I0830 18:22:22.974429 10575 net.cpp:112] conv2 -> conv2
I0830 18:22:22.986627 10575 net.cpp:127] Top shape: 128 256 27 27 (23887872)
I0830 18:22:22.986654 10575 net.cpp:153] conv2 needs backward computation.
I0830 18:22:22.986662 10575 net.cpp:76] Creating Layer relu2
I0830 18:22:22.986668 10575 net.cpp:86] relu2 <- conv2
I0830 18:22:22.986675 10575 net.cpp:100] relu2 -> conv2 (in-place)
I0830 18:22:22.986681 10575 net.cpp:127] Top shape: 128 256 27 27 (23887872)
I0830 18:22:22.986686 10575 net.cpp:153] relu2 needs backward computation.
I0830 18:22:22.986692 10575 net.cpp:76] Creating Layer pool2
I0830 18:22:22.986696 10575 net.cpp:86] pool2 <- conv2
I0830 18:22:22.986701 10575 net.cpp:112] pool2 -> pool2
I0830 18:22:22.986708 10575 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0830 18:22:22.986712 10575 net.cpp:153] pool2 needs backward computation.
I0830 18:22:22.986721 10575 net.cpp:76] Creating Layer norm2
I0830 18:22:22.986726 10575 net.cpp:86] norm2 <- pool2
I0830 18:22:22.986732 10575 net.cpp:112] norm2 -> norm2
I0830 18:22:22.986737 10575 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0830 18:22:22.986742 10575 net.cpp:153] norm2 needs backward computation.
I0830 18:22:22.986748 10575 net.cpp:76] Creating Layer conv3
I0830 18:22:22.986752 10575 net.cpp:86] conv3 <- norm2
I0830 18:22:22.986757 10575 net.cpp:112] conv3 -> conv3
I0830 18:22:23.023052 10575 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0830 18:22:23.023077 10575 net.cpp:153] conv3 needs backward computation.
I0830 18:22:23.023085 10575 net.cpp:76] Creating Layer relu3
I0830 18:22:23.023092 10575 net.cpp:86] relu3 <- conv3
I0830 18:22:23.023098 10575 net.cpp:100] relu3 -> conv3 (in-place)
I0830 18:22:23.023104 10575 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0830 18:22:23.023108 10575 net.cpp:153] relu3 needs backward computation.
I0830 18:22:23.023115 10575 net.cpp:76] Creating Layer conv4
I0830 18:22:23.023119 10575 net.cpp:86] conv4 <- conv3
I0830 18:22:23.023124 10575 net.cpp:112] conv4 -> conv4
I0830 18:22:23.050462 10575 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0830 18:22:23.050488 10575 net.cpp:153] conv4 needs backward computation.
I0830 18:22:23.050497 10575 net.cpp:76] Creating Layer relu4
I0830 18:22:23.050503 10575 net.cpp:86] relu4 <- conv4
I0830 18:22:23.050509 10575 net.cpp:100] relu4 -> conv4 (in-place)
I0830 18:22:23.050518 10575 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0830 18:22:23.050526 10575 net.cpp:153] relu4 needs backward computation.
I0830 18:22:23.050537 10575 net.cpp:76] Creating Layer conv5
I0830 18:22:23.050541 10575 net.cpp:86] conv5 <- conv4
I0830 18:22:23.050546 10575 net.cpp:112] conv5 -> conv5
I0830 18:22:23.068832 10575 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0830 18:22:23.068858 10575 net.cpp:153] conv5 needs backward computation.
I0830 18:22:23.068867 10575 net.cpp:76] Creating Layer relu5
I0830 18:22:23.068872 10575 net.cpp:86] relu5 <- conv5
I0830 18:22:23.068879 10575 net.cpp:100] relu5 -> conv5 (in-place)
I0830 18:22:23.068884 10575 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0830 18:22:23.068889 10575 net.cpp:153] relu5 needs backward computation.
I0830 18:22:23.068894 10575 net.cpp:76] Creating Layer pool5
I0830 18:22:23.068898 10575 net.cpp:86] pool5 <- conv5
I0830 18:22:23.068903 10575 net.cpp:112] pool5 -> pool5
I0830 18:22:23.068910 10575 net.cpp:127] Top shape: 128 256 6 6 (1179648)
I0830 18:22:23.068915 10575 net.cpp:153] pool5 needs backward computation.
I0830 18:22:23.068924 10575 net.cpp:76] Creating Layer fc6
I0830 18:22:23.068929 10575 net.cpp:86] fc6 <- pool5
I0830 18:22:23.068934 10575 net.cpp:112] fc6 -> fc6
I0830 18:22:24.611394 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:24.611423 10575 net.cpp:153] fc6 needs backward computation.
I0830 18:22:24.611431 10575 net.cpp:76] Creating Layer relu6
I0830 18:22:24.611438 10575 net.cpp:86] relu6 <- fc6
I0830 18:22:24.611445 10575 net.cpp:100] relu6 -> fc6 (in-place)
I0830 18:22:24.611451 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:24.611455 10575 net.cpp:153] relu6 needs backward computation.
I0830 18:22:24.611461 10575 net.cpp:76] Creating Layer drop6
I0830 18:22:24.611465 10575 net.cpp:86] drop6 <- fc6
I0830 18:22:24.611469 10575 net.cpp:100] drop6 -> fc6 (in-place)
I0830 18:22:24.611475 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:24.611480 10575 net.cpp:153] drop6 needs backward computation.
I0830 18:22:24.611486 10575 net.cpp:76] Creating Layer fc7
I0830 18:22:24.611490 10575 net.cpp:86] fc7 <- fc6
I0830 18:22:24.611495 10575 net.cpp:112] fc7 -> fc7
I0830 18:22:25.296816 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:25.296844 10575 net.cpp:153] fc7 needs backward computation.
I0830 18:22:25.296852 10575 net.cpp:76] Creating Layer relu7
I0830 18:22:25.296859 10575 net.cpp:86] relu7 <- fc7
I0830 18:22:25.296865 10575 net.cpp:100] relu7 -> fc7 (in-place)
I0830 18:22:25.296872 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:25.296876 10575 net.cpp:153] relu7 needs backward computation.
I0830 18:22:25.296882 10575 net.cpp:76] Creating Layer drop7
I0830 18:22:25.296886 10575 net.cpp:86] drop7 <- fc7
I0830 18:22:25.296891 10575 net.cpp:100] drop7 -> fc7 (in-place)
I0830 18:22:25.296896 10575 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0830 18:22:25.296900 10575 net.cpp:153] drop7 needs backward computation.
I0830 18:22:25.296906 10575 net.cpp:76] Creating Layer fc8_hatch
I0830 18:22:25.296911 10575 net.cpp:86] fc8_hatch <- fc7
I0830 18:22:25.296916 10575 net.cpp:112] fc8_hatch -> fc8_hatch
I0830 18:22:25.297250 10575 net.cpp:127] Top shape: 128 2 1 1 (256)
I0830 18:22:25.297256 10575 net.cpp:153] fc8_hatch needs backward computation.
I0830 18:22:25.297262 10575 net.cpp:76] Creating Layer prob
I0830 18:22:25.297267 10575 net.cpp:86] prob <- fc8_hatch
I0830 18:22:25.297272 10575 net.cpp:112] prob -> prob
I0830 18:22:25.297279 10575 net.cpp:127] Top shape: 128 2 1 1 (256)
I0830 18:22:25.297283 10575 net.cpp:153] prob needs backward computation.
I0830 18:22:25.297288 10575 net.cpp:76] Creating Layer accuracy
I0830 18:22:25.297293 10575 net.cpp:86] accuracy <- prob
I0830 18:22:25.297298 10575 net.cpp:86] accuracy <- label
I0830 18:22:25.297304 10575 net.cpp:112] accuracy -> accuracy
I0830 18:22:25.297319 10575 net.cpp:127] Top shape: 1 2 1 1 (2)
I0830 18:22:25.297325 10575 net.cpp:153] accuracy needs backward computation.
I0830 18:22:25.297329 10575 net.cpp:164] This network produces output accuracy
I0830 18:22:25.297348 10575 net.cpp:182] Collecting Learning Rate and Weight Decay.
I0830 18:22:25.297361 10575 net.cpp:175] Network initialization done.
I0830 18:22:25.297369 10575 net.cpp:176] Memory required for Data 536870920
I0830 18:22:25.297430 10575 solver.cpp:50] Solver scaffolding done.
I0830 18:22:25.297441 10575 finetune_net.cpp:27] Loading from /homes/ad6813/net-saves/clampdet/none/clampdet_6000
I0830 18:22:25.929770 10575 net.cpp:366] Copying source layer data
I0830 18:22:25.929798 10575 net.cpp:366] Copying source layer conv1
I0830 18:22:25.929868 10575 net.cpp:366] Copying source layer relu1
I0830 18:22:25.929878 10575 net.cpp:366] Copying source layer pool1
I0830 18:22:25.929883 10575 net.cpp:366] Copying source layer norm1
I0830 18:22:25.929886 10575 net.cpp:366] Copying source layer conv2
I0830 18:22:25.930424 10575 net.cpp:366] Copying source layer relu2
I0830 18:22:25.930436 10575 net.cpp:366] Copying source layer pool2
I0830 18:22:25.930441 10575 net.cpp:366] Copying source layer norm2
I0830 18:22:25.930445 10575 net.cpp:366] Copying source layer conv3
I0830 18:22:25.931931 10575 net.cpp:366] Copying source layer relu3
I0830 18:22:25.931946 10575 net.cpp:366] Copying source layer conv4
I0830 18:22:25.933068 10575 net.cpp:366] Copying source layer relu4
I0830 18:22:25.933079 10575 net.cpp:366] Copying source layer conv5
I0830 18:22:25.933869 10575 net.cpp:366] Copying source layer relu5
I0830 18:22:25.933881 10575 net.cpp:366] Copying source layer pool5
I0830 18:22:25.933886 10575 net.cpp:366] Copying source layer fc6
I0830 18:22:26.055440 10575 net.cpp:366] Copying source layer relu6
I0830 18:22:26.055472 10575 net.cpp:366] Copying source layer drop6
I0830 18:22:26.055479 10575 net.cpp:366] Copying source layer fc7
I0830 18:22:26.109213 10575 net.cpp:366] Copying source layer relu7
I0830 18:22:26.109246 10575 net.cpp:366] Copying source layer drop7
I0830 18:22:26.109249 10575 net.cpp:363] Ignoring source layer fc8_new
I0830 18:22:26.109254 10575 net.cpp:366] Copying source layer loss
I0830 18:22:26.124542 10575 solver.cpp:62] Solving hatch_markingsFineNet
I0830 18:22:26.124575 10575 solver.cpp:136] Iteration 0, Testing net
I0830 18:22:27.920601 10575 solver.cpp:172] Test score #0: 0.495715
I0830 18:22:27.920663 10575 solver.cpp:172] Test score #1: 0.729019
Terminated
Done.
