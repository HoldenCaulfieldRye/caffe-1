nohup: ignoring input
I0829 05:08:13.293992 15446 finetune_net.cpp:25] Starting Optimization
I0829 05:08:13.294080 15446 solver.cpp:42] Creating training net.
I0829 05:08:13.294569 15446 net.cpp:76] Creating Layer data
I0829 05:08:13.294580 15446 net.cpp:112] data -> data
I0829 05:08:13.294591 15446 net.cpp:112] data -> label
I0829 05:08:13.294611 15446 data_layer.cpp:145] Opening leveldb clampdetCI_train_leveldb
I0829 05:08:13.337952 15446 data_layer.cpp:185] output data size: 128,3,227,227
I0829 05:08:13.337970 15446 data_layer.cpp:204] Loading mean file from../../data/clampdetCI/clampdetCI_mean.binaryproto
I0829 05:08:13.559512 15446 net.cpp:127] Top shape: 128 3 227 227 (19787136)
I0829 05:08:13.559543 15446 net.cpp:127] Top shape: 128 1 1 1 (128)
I0829 05:08:13.559551 15446 net.cpp:158] data does not need backward computation.
I0829 05:08:13.559563 15446 net.cpp:76] Creating Layer conv1
I0829 05:08:13.559569 15446 net.cpp:86] conv1 <- data
I0829 05:08:13.559583 15446 net.cpp:112] conv1 -> conv1
I0829 05:08:13.560916 15446 net.cpp:127] Top shape: 128 96 55 55 (37171200)
I0829 05:08:13.560931 15446 net.cpp:153] conv1 needs backward computation.
I0829 05:08:13.560940 15446 net.cpp:76] Creating Layer relu1
I0829 05:08:13.560943 15446 net.cpp:86] relu1 <- conv1
I0829 05:08:13.560950 15446 net.cpp:100] relu1 -> conv1 (in-place)
I0829 05:08:13.560956 15446 net.cpp:127] Top shape: 128 96 55 55 (37171200)
I0829 05:08:13.560963 15446 net.cpp:153] relu1 needs backward computation.
I0829 05:08:13.560977 15446 net.cpp:76] Creating Layer pool1
I0829 05:08:13.560986 15446 net.cpp:86] pool1 <- conv1
I0829 05:08:13.560993 15446 net.cpp:112] pool1 -> pool1
I0829 05:08:13.561010 15446 net.cpp:127] Top shape: 128 96 27 27 (8957952)
I0829 05:08:13.561019 15446 net.cpp:153] pool1 needs backward computation.
I0829 05:08:13.561030 15446 net.cpp:76] Creating Layer norm1
I0829 05:08:13.561038 15446 net.cpp:86] norm1 <- pool1
I0829 05:08:13.561054 15446 net.cpp:112] norm1 -> norm1
I0829 05:08:13.561069 15446 net.cpp:127] Top shape: 128 96 27 27 (8957952)
I0829 05:08:13.561079 15446 net.cpp:153] norm1 needs backward computation.
I0829 05:08:13.561089 15446 net.cpp:76] Creating Layer conv2
I0829 05:08:13.561105 15446 net.cpp:86] conv2 <- norm1
I0829 05:08:13.561113 15446 net.cpp:112] conv2 -> conv2
I0829 05:08:13.572510 15446 net.cpp:127] Top shape: 128 256 27 27 (23887872)
I0829 05:08:13.572541 15446 net.cpp:153] conv2 needs backward computation.
I0829 05:08:13.572554 15446 net.cpp:76] Creating Layer relu2
I0829 05:08:13.572563 15446 net.cpp:86] relu2 <- conv2
I0829 05:08:13.572572 15446 net.cpp:100] relu2 -> conv2 (in-place)
I0829 05:08:13.572579 15446 net.cpp:127] Top shape: 128 256 27 27 (23887872)
I0829 05:08:13.572587 15446 net.cpp:153] relu2 needs backward computation.
I0829 05:08:13.572595 15446 net.cpp:76] Creating Layer pool2
I0829 05:08:13.572602 15446 net.cpp:86] pool2 <- conv2
I0829 05:08:13.572609 15446 net.cpp:112] pool2 -> pool2
I0829 05:08:13.572618 15446 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0829 05:08:13.572624 15446 net.cpp:153] pool2 needs backward computation.
I0829 05:08:13.572636 15446 net.cpp:76] Creating Layer norm2
I0829 05:08:13.572643 15446 net.cpp:86] norm2 <- pool2
I0829 05:08:13.572650 15446 net.cpp:112] norm2 -> norm2
I0829 05:08:13.572660 15446 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0829 05:08:13.572669 15446 net.cpp:153] norm2 needs backward computation.
I0829 05:08:13.572691 15446 net.cpp:76] Creating Layer conv3
I0829 05:08:13.572700 15446 net.cpp:86] conv3 <- norm2
I0829 05:08:13.572706 15446 net.cpp:112] conv3 -> conv3
I0829 05:08:13.605339 15446 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0829 05:08:13.605371 15446 net.cpp:153] conv3 needs backward computation.
I0829 05:08:13.605383 15446 net.cpp:76] Creating Layer relu3
I0829 05:08:13.605391 15446 net.cpp:86] relu3 <- conv3
I0829 05:08:13.605401 15446 net.cpp:100] relu3 -> conv3 (in-place)
I0829 05:08:13.605409 15446 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0829 05:08:13.605415 15446 net.cpp:153] relu3 needs backward computation.
I0829 05:08:13.605424 15446 net.cpp:76] Creating Layer conv4
I0829 05:08:13.605430 15446 net.cpp:86] conv4 <- conv3
I0829 05:08:13.605437 15446 net.cpp:112] conv4 -> conv4
I0829 05:08:13.636188 15446 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0829 05:08:13.636220 15446 net.cpp:153] conv4 needs backward computation.
I0829 05:08:13.636230 15446 net.cpp:76] Creating Layer relu4
I0829 05:08:13.636236 15446 net.cpp:86] relu4 <- conv4
I0829 05:08:13.636243 15446 net.cpp:100] relu4 -> conv4 (in-place)
I0829 05:08:13.636250 15446 net.cpp:127] Top shape: 128 384 13 13 (8306688)
I0829 05:08:13.636253 15446 net.cpp:153] relu4 needs backward computation.
I0829 05:08:13.636260 15446 net.cpp:76] Creating Layer conv5
I0829 05:08:13.636263 15446 net.cpp:86] conv5 <- conv4
I0829 05:08:13.636268 15446 net.cpp:112] conv5 -> conv5
I0829 05:08:13.652312 15446 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0829 05:08:13.652338 15446 net.cpp:153] conv5 needs backward computation.
I0829 05:08:13.652345 15446 net.cpp:76] Creating Layer relu5
I0829 05:08:13.652351 15446 net.cpp:86] relu5 <- conv5
I0829 05:08:13.652358 15446 net.cpp:100] relu5 -> conv5 (in-place)
I0829 05:08:13.652362 15446 net.cpp:127] Top shape: 128 256 13 13 (5537792)
I0829 05:08:13.652366 15446 net.cpp:153] relu5 needs backward computation.
I0829 05:08:13.652371 15446 net.cpp:76] Creating Layer pool5
I0829 05:08:13.652375 15446 net.cpp:86] pool5 <- conv5
I0829 05:08:13.652380 15446 net.cpp:112] pool5 -> pool5
I0829 05:08:13.652386 15446 net.cpp:127] Top shape: 128 256 6 6 (1179648)
I0829 05:08:13.652391 15446 net.cpp:153] pool5 needs backward computation.
I0829 05:08:13.652400 15446 net.cpp:76] Creating Layer fc6
I0829 05:08:13.652403 15446 net.cpp:86] fc6 <- pool5
I0829 05:08:13.652408 15446 net.cpp:112] fc6 -> fc6
I0829 05:08:15.013424 15446 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0829 05:08:15.013454 15446 net.cpp:153] fc6 needs backward computation.
I0829 05:08:15.013464 15446 net.cpp:76] Creating Layer relu6
I0829 05:08:15.013470 15446 net.cpp:86] relu6 <- fc6
I0829 05:08:15.013478 15446 net.cpp:100] relu6 -> fc6 (in-place)
I0829 05:08:15.013483 15446 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0829 05:08:15.013486 15446 net.cpp:153] relu6 needs backward computation.
I0829 05:08:15.013492 15446 net.cpp:76] Creating Layer drop6
I0829 05:08:15.013496 15446 net.cpp:86] drop6 <- fc6
I0829 05:08:15.013500 15446 net.cpp:100] drop6 -> fc6 (in-place)
I0829 05:08:15.013514 15446 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0829 05:08:15.013517 15446 net.cpp:153] drop6 needs backward computation.
I0829 05:08:15.013523 15446 net.cpp:76] Creating Layer fc7
I0829 05:08:15.013527 15446 net.cpp:86] fc7 <- fc6
I0829 05:08:15.013532 15446 net.cpp:112] fc7 -> fc7
I0829 05:08:15.619087 15446 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0829 05:08:15.619119 15446 net.cpp:153] fc7 needs backward computation.
I0829 05:08:15.619128 15446 net.cpp:76] Creating Layer relu7
I0829 05:08:15.619134 15446 net.cpp:86] relu7 <- fc7
I0829 05:08:15.619141 15446 net.cpp:100] relu7 -> fc7 (in-place)
I0829 05:08:15.619146 15446 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0829 05:08:15.619150 15446 net.cpp:153] relu7 needs backward computation.
I0829 05:08:15.619156 15446 net.cpp:76] Creating Layer drop7
I0829 05:08:15.619159 15446 net.cpp:86] drop7 <- fc7
I0829 05:08:15.619164 15446 net.cpp:100] drop7 -> fc7 (in-place)
I0829 05:08:15.619168 15446 net.cpp:127] Top shape: 128 4096 1 1 (524288)
I0829 05:08:15.619177 15446 net.cpp:153] drop7 needs backward computation.
I0829 05:08:15.619187 15446 net.cpp:76] Creating Layer fc8_new
I0829 05:08:15.619194 15446 net.cpp:86] fc8_new <- fc7
I0829 05:08:15.619201 15446 net.cpp:112] fc8_new -> fc8_new
I0829 05:08:15.619536 15446 net.cpp:127] Top shape: 128 2 1 1 (256)
I0829 05:08:15.619546 15446 net.cpp:153] fc8_new needs backward computation.
I0829 05:08:15.619552 15446 net.cpp:76] Creating Layer loss
I0829 05:08:15.619557 15446 net.cpp:86] loss <- fc8_new
I0829 05:08:15.619562 15446 net.cpp:86] loss <- label
I0829 05:08:15.619571 15446 net.cpp:153] loss needs backward computation.
I0829 05:08:15.619599 15446 net.cpp:182] Collecting Learning Rate and Weight Decay.
I0829 05:08:15.619616 15446 net.cpp:175] Network initialization done.
I0829 05:08:15.619623 15446 net.cpp:176] Memory required for Data 536869888
I0829 05:08:15.619676 15446 solver.cpp:45] Creating testing net.
I0829 05:08:15.620234 15446 net.cpp:76] Creating Layer data
I0829 05:08:15.620244 15446 net.cpp:112] data -> data
I0829 05:08:15.620251 15446 net.cpp:112] data -> label
I0829 05:08:15.620259 15446 data_layer.cpp:145] Opening leveldb clampdetCI_val_leveldb
I0829 05:08:15.671269 15446 data_layer.cpp:185] output data size: 293,3,227,227
I0829 05:08:15.671293 15446 data_layer.cpp:204] Loading mean file from../../data/clampdetCI/clampdetCI_mean.binaryproto
I0829 05:08:15.751706 15446 net.cpp:127] Top shape: 293 3 227 227 (45293991)
I0829 05:08:15.751735 15446 net.cpp:127] Top shape: 293 1 1 1 (293)
I0829 05:08:15.751741 15446 net.cpp:158] data does not need backward computation.
I0829 05:08:15.751755 15446 net.cpp:76] Creating Layer conv1
I0829 05:08:15.751761 15446 net.cpp:86] conv1 <- data
I0829 05:08:15.751768 15446 net.cpp:112] conv1 -> conv1
I0829 05:08:15.752995 15446 net.cpp:127] Top shape: 293 96 55 55 (85087200)
I0829 05:08:15.753005 15446 net.cpp:153] conv1 needs backward computation.
I0829 05:08:15.753010 15446 net.cpp:76] Creating Layer relu1
I0829 05:08:15.753015 15446 net.cpp:86] relu1 <- conv1
I0829 05:08:15.753020 15446 net.cpp:100] relu1 -> conv1 (in-place)
I0829 05:08:15.753025 15446 net.cpp:127] Top shape: 293 96 55 55 (85087200)
I0829 05:08:15.753029 15446 net.cpp:153] relu1 needs backward computation.
I0829 05:08:15.753034 15446 net.cpp:76] Creating Layer pool1
I0829 05:08:15.753038 15446 net.cpp:86] pool1 <- conv1
I0829 05:08:15.753042 15446 net.cpp:112] pool1 -> pool1
I0829 05:08:15.753048 15446 net.cpp:127] Top shape: 293 96 27 27 (20505312)
I0829 05:08:15.753052 15446 net.cpp:153] pool1 needs backward computation.
I0829 05:08:15.753059 15446 net.cpp:76] Creating Layer norm1
I0829 05:08:15.753067 15446 net.cpp:86] norm1 <- pool1
I0829 05:08:15.753075 15446 net.cpp:112] norm1 -> norm1
I0829 05:08:15.753087 15446 net.cpp:127] Top shape: 293 96 27 27 (20505312)
I0829 05:08:15.753094 15446 net.cpp:153] norm1 needs backward computation.
I0829 05:08:15.753104 15446 net.cpp:76] Creating Layer conv2
I0829 05:08:15.753113 15446 net.cpp:86] conv2 <- norm1
I0829 05:08:15.753121 15446 net.cpp:112] conv2 -> conv2
I0829 05:08:15.763885 15446 net.cpp:127] Top shape: 293 256 27 27 (54680832)
I0829 05:08:15.763912 15446 net.cpp:153] conv2 needs backward computation.
I0829 05:08:15.763924 15446 net.cpp:76] Creating Layer relu2
I0829 05:08:15.763932 15446 net.cpp:86] relu2 <- conv2
I0829 05:08:15.763942 15446 net.cpp:100] relu2 -> conv2 (in-place)
I0829 05:08:15.763952 15446 net.cpp:127] Top shape: 293 256 27 27 (54680832)
I0829 05:08:15.763957 15446 net.cpp:153] relu2 needs backward computation.
I0829 05:08:15.763967 15446 net.cpp:76] Creating Layer pool2
I0829 05:08:15.763974 15446 net.cpp:86] pool2 <- conv2
I0829 05:08:15.763981 15446 net.cpp:112] pool2 -> pool2
I0829 05:08:15.763994 15446 net.cpp:127] Top shape: 293 256 13 13 (12676352)
I0829 05:08:15.764003 15446 net.cpp:153] pool2 needs backward computation.
I0829 05:08:15.764016 15446 net.cpp:76] Creating Layer norm2
I0829 05:08:15.764024 15446 net.cpp:86] norm2 <- pool2
I0829 05:08:15.764032 15446 net.cpp:112] norm2 -> norm2
I0829 05:08:15.764044 15446 net.cpp:127] Top shape: 293 256 13 13 (12676352)
I0829 05:08:15.764052 15446 net.cpp:153] norm2 needs backward computation.
I0829 05:08:15.764062 15446 net.cpp:76] Creating Layer conv3
I0829 05:08:15.764070 15446 net.cpp:86] conv3 <- norm2
I0829 05:08:15.764078 15446 net.cpp:112] conv3 -> conv3
I0829 05:08:15.796154 15446 net.cpp:127] Top shape: 293 384 13 13 (19014528)
I0829 05:08:15.796181 15446 net.cpp:153] conv3 needs backward computation.
I0829 05:08:15.796193 15446 net.cpp:76] Creating Layer relu3
I0829 05:08:15.796202 15446 net.cpp:86] relu3 <- conv3
I0829 05:08:15.796213 15446 net.cpp:100] relu3 -> conv3 (in-place)
I0829 05:08:15.796221 15446 net.cpp:127] Top shape: 293 384 13 13 (19014528)
I0829 05:08:15.796228 15446 net.cpp:153] relu3 needs backward computation.
I0829 05:08:15.796238 15446 net.cpp:76] Creating Layer conv4
I0829 05:08:15.796244 15446 net.cpp:86] conv4 <- conv3
I0829 05:08:15.796252 15446 net.cpp:112] conv4 -> conv4
I0829 05:08:15.820272 15446 net.cpp:127] Top shape: 293 384 13 13 (19014528)
I0829 05:08:15.820302 15446 net.cpp:153] conv4 needs backward computation.
I0829 05:08:15.820313 15446 net.cpp:76] Creating Layer relu4
I0829 05:08:15.820322 15446 net.cpp:86] relu4 <- conv4
I0829 05:08:15.820333 15446 net.cpp:100] relu4 -> conv4 (in-place)
I0829 05:08:15.820340 15446 net.cpp:127] Top shape: 293 384 13 13 (19014528)
I0829 05:08:15.820346 15446 net.cpp:153] relu4 needs backward computation.
I0829 05:08:15.820355 15446 net.cpp:76] Creating Layer conv5
I0829 05:08:15.820361 15446 net.cpp:86] conv5 <- conv4
I0829 05:08:15.820372 15446 net.cpp:112] conv5 -> conv5
I0829 05:08:15.836396 15446 net.cpp:127] Top shape: 293 256 13 13 (12676352)
I0829 05:08:15.836423 15446 net.cpp:153] conv5 needs backward computation.
I0829 05:08:15.836436 15446 net.cpp:76] Creating Layer relu5
I0829 05:08:15.836443 15446 net.cpp:86] relu5 <- conv5
I0829 05:08:15.836453 15446 net.cpp:100] relu5 -> conv5 (in-place)
I0829 05:08:15.836462 15446 net.cpp:127] Top shape: 293 256 13 13 (12676352)
I0829 05:08:15.836468 15446 net.cpp:153] relu5 needs backward computation.
I0829 05:08:15.836477 15446 net.cpp:76] Creating Layer pool5
I0829 05:08:15.836483 15446 net.cpp:86] pool5 <- conv5
I0829 05:08:15.836491 15446 net.cpp:112] pool5 -> pool5
I0829 05:08:15.836503 15446 net.cpp:127] Top shape: 293 256 6 6 (2700288)
I0829 05:08:15.836510 15446 net.cpp:153] pool5 needs backward computation.
I0829 05:08:15.836525 15446 net.cpp:76] Creating Layer fc6
I0829 05:08:15.836532 15446 net.cpp:86] fc6 <- pool5
I0829 05:08:15.836541 15446 net.cpp:112] fc6 -> fc6
I0829 05:08:17.198529 15446 net.cpp:127] Top shape: 293 4096 1 1 (1200128)
I0829 05:08:17.198559 15446 net.cpp:153] fc6 needs backward computation.
I0829 05:08:17.198570 15446 net.cpp:76] Creating Layer relu6
I0829 05:08:17.198575 15446 net.cpp:86] relu6 <- fc6
I0829 05:08:17.198581 15446 net.cpp:100] relu6 -> fc6 (in-place)
I0829 05:08:17.198587 15446 net.cpp:127] Top shape: 293 4096 1 1 (1200128)
I0829 05:08:17.198591 15446 net.cpp:153] relu6 needs backward computation.
I0829 05:08:17.198597 15446 net.cpp:76] Creating Layer drop6
I0829 05:08:17.198601 15446 net.cpp:86] drop6 <- fc6
I0829 05:08:17.198606 15446 net.cpp:100] drop6 -> fc6 (in-place)
I0829 05:08:17.198614 15446 net.cpp:127] Top shape: 293 4096 1 1 (1200128)
I0829 05:08:17.198621 15446 net.cpp:153] drop6 needs backward computation.
I0829 05:08:17.198632 15446 net.cpp:76] Creating Layer fc7
I0829 05:08:17.198637 15446 net.cpp:86] fc7 <- fc6
I0829 05:08:17.198645 15446 net.cpp:112] fc7 -> fc7
I0829 05:08:17.803022 15446 net.cpp:127] Top shape: 293 4096 1 1 (1200128)
I0829 05:08:17.803050 15446 net.cpp:153] fc7 needs backward computation.
I0829 05:08:17.803060 15446 net.cpp:76] Creating Layer relu7
I0829 05:08:17.803064 15446 net.cpp:86] relu7 <- fc7
I0829 05:08:17.803071 15446 net.cpp:100] relu7 -> fc7 (in-place)
I0829 05:08:17.803076 15446 net.cpp:127] Top shape: 293 4096 1 1 (1200128)
I0829 05:08:17.803081 15446 net.cpp:153] relu7 needs backward computation.
I0829 05:08:17.803086 15446 net.cpp:76] Creating Layer drop7
I0829 05:08:17.803089 15446 net.cpp:86] drop7 <- fc7
I0829 05:08:17.803094 15446 net.cpp:100] drop7 -> fc7 (in-place)
I0829 05:08:17.803099 15446 net.cpp:127] Top shape: 293 4096 1 1 (1200128)
I0829 05:08:17.803103 15446 net.cpp:153] drop7 needs backward computation.
I0829 05:08:17.803108 15446 net.cpp:76] Creating Layer fc8_new
I0829 05:08:17.803112 15446 net.cpp:86] fc8_new <- fc7
I0829 05:08:17.803117 15446 net.cpp:112] fc8_new -> fc8_new
I0829 05:08:17.803412 15446 net.cpp:127] Top shape: 293 2 1 1 (586)
I0829 05:08:17.803419 15446 net.cpp:153] fc8_new needs backward computation.
I0829 05:08:17.803426 15446 net.cpp:76] Creating Layer prob
I0829 05:08:17.803429 15446 net.cpp:86] prob <- fc8_new
I0829 05:08:17.803434 15446 net.cpp:112] prob -> prob
I0829 05:08:17.803441 15446 net.cpp:127] Top shape: 293 2 1 1 (586)
I0829 05:08:17.803446 15446 net.cpp:153] prob needs backward computation.
I0829 05:08:17.803450 15446 net.cpp:76] Creating Layer accuracy
I0829 05:08:17.803454 15446 net.cpp:86] accuracy <- prob
I0829 05:08:17.803458 15446 net.cpp:86] accuracy <- label
I0829 05:08:17.803463 15446 net.cpp:112] accuracy -> accuracy
I0829 05:08:17.803478 15446 net.cpp:127] Top shape: 1 2 1 1 (2)
I0829 05:08:17.803481 15446 net.cpp:153] accuracy needs backward computation.
I0829 05:08:17.803485 15446 net.cpp:164] This network produces output accuracy
I0829 05:08:17.803503 15446 net.cpp:182] Collecting Learning Rate and Weight Decay.
I0829 05:08:17.803513 15446 net.cpp:175] Network initialization done.
I0829 05:08:17.803516 15446 net.cpp:176] Memory required for Data 1228931080
I0829 05:08:17.803552 15446 solver.cpp:50] Solver scaffolding done.
I0829 05:08:17.803560 15446 finetune_net.cpp:27] Loading from ../alexnet/caffe_alexnet_model
I0829 05:08:18.378362 15446 net.cpp:366] Copying source layer data
I0829 05:08:18.378389 15446 net.cpp:366] Copying source layer conv1
I0829 05:08:18.378453 15446 net.cpp:366] Copying source layer relu1
I0829 05:08:18.378458 15446 net.cpp:366] Copying source layer norm1
I0829 05:08:18.378463 15446 net.cpp:366] Copying source layer pool1
I0829 05:08:18.378466 15446 net.cpp:366] Copying source layer conv2
I0829 05:08:18.378972 15446 net.cpp:366] Copying source layer relu2
I0829 05:08:18.378981 15446 net.cpp:366] Copying source layer norm2
I0829 05:08:18.378985 15446 net.cpp:366] Copying source layer pool2
I0829 05:08:18.378989 15446 net.cpp:366] Copying source layer conv3
I0829 05:08:18.380334 15446 net.cpp:366] Copying source layer relu3
I0829 05:08:18.380347 15446 net.cpp:366] Copying source layer conv4
I0829 05:08:18.381361 15446 net.cpp:366] Copying source layer relu4
I0829 05:08:18.381371 15446 net.cpp:366] Copying source layer conv5
I0829 05:08:18.382077 15446 net.cpp:366] Copying source layer relu5
I0829 05:08:18.382087 15446 net.cpp:366] Copying source layer pool5
I0829 05:08:18.382091 15446 net.cpp:366] Copying source layer fc6
I0829 05:08:18.489087 15446 net.cpp:366] Copying source layer relu6
I0829 05:08:18.489116 15446 net.cpp:366] Copying source layer drop6
I0829 05:08:18.489121 15446 net.cpp:366] Copying source layer fc7
I0829 05:08:18.536077 15446 net.cpp:366] Copying source layer relu7
I0829 05:08:18.536108 15446 net.cpp:366] Copying source layer drop7
I0829 05:08:18.536111 15446 net.cpp:363] Ignoring source layer fc8
I0829 05:08:18.536115 15446 net.cpp:366] Copying source layer loss
I0829 05:08:18.548526 15446 solver.cpp:62] Solving clampdetCIFineNet
I0829 05:08:18.548555 15446 solver.cpp:136] Iteration 0, Testing net
I0829 05:08:19.788506 15446 solver.cpp:172] Test score #0: 0.357894
I0829 05:08:19.788564 15446 solver.cpp:172] Test score #1: 0.551713
I0829 05:08:20.840883 15446 solver.cpp:269] Iteration 1, lr = 5e-06
I0829 05:08:21.071287 15446 solver.cpp:117] Iteration 1, loss = 0.709373
I0829 05:08:22.552546 15446 solver.cpp:269] Iteration 2, lr = 5e-06
I0829 05:08:22.744762 15446 solver.cpp:117] Iteration 2, loss = 0.71447
I0829 05:08:24.205099 15446 solver.cpp:269] Iteration 3, lr = 5e-06
I0829 05:08:24.454324 15446 solver.cpp:117] Iteration 3, loss = 0.653588
I0829 05:08:25.886376 15446 solver.cpp:269] Iteration 4, lr = 5e-06
I0829 05:08:26.113215 15446 solver.cpp:117] Iteration 4, loss = 0.61082
I0829 05:08:27.588768 15446 solver.cpp:269] Iteration 5, lr = 5e-06
I0829 05:08:27.783370 15446 solver.cpp:117] Iteration 5, loss = 0.613753
I0829 05:08:27.783406 15446 solver.cpp:136] Iteration 5, Testing net
I0829 05:08:29.259507 15446 solver.cpp:172] Test score #0: 0.676326
I0829 05:08:29.259531 15446 solver.cpp:172] Test score #1: 0.543576
I0829 05:08:30.293673 15446 solver.cpp:269] Iteration 6, lr = 5e-06
I0829 05:08:30.543414 15446 solver.cpp:117] Iteration 6, loss = 0.611292
I0829 05:08:31.980782 15446 solver.cpp:269] Iteration 7, lr = 5e-06
I0829 05:08:32.209485 15446 solver.cpp:117] Iteration 7, loss = 0.607182
I0829 05:08:33.690963 15446 solver.cpp:269] Iteration 8, lr = 5e-06
I0829 05:08:33.883754 15446 solver.cpp:117] Iteration 8, loss = 0.642287
I0829 05:08:35.340199 15446 solver.cpp:269] Iteration 9, lr = 5e-06
I0829 05:08:35.587347 15446 solver.cpp:117] Iteration 9, loss = 0.601871
I0829 05:08:37.016633 15446 solver.cpp:269] Iteration 10, lr = 5e-06
I0829 05:08:37.245764 15446 solver.cpp:117] Iteration 10, loss = 0.601288
I0829 05:08:37.245779 15446 solver.cpp:136] Iteration 10, Testing net
I0829 05:08:38.737665 15446 solver.cpp:172] Test score #0: 0.496675
I0829 05:08:38.737689 15446 solver.cpp:172] Test score #1: 0.54821
I0829 05:08:39.767109 15446 solver.cpp:269] Iteration 11, lr = 5e-06
I0829 05:08:39.957975 15446 solver.cpp:117] Iteration 11, loss = 0.594035
I0829 05:08:41.417637 15446 solver.cpp:269] Iteration 12, lr = 5e-06
I0829 05:08:41.664152 15446 solver.cpp:117] Iteration 12, loss = 0.624468
I0829 05:08:43.100924 15446 solver.cpp:269] Iteration 13, lr = 5e-06
I0829 05:08:43.327937 15446 solver.cpp:117] Iteration 13, loss = 0.60623
I0829 05:08:44.804378 15446 solver.cpp:269] Iteration 14, lr = 5e-06
I0829 05:08:44.997206 15446 solver.cpp:117] Iteration 14, loss = 0.569311
I0829 05:08:46.438524 15446 solver.cpp:269] Iteration 15, lr = 5e-06
I0829 05:08:46.677723 15446 solver.cpp:117] Iteration 15, loss = 0.591055
I0829 05:08:46.677739 15446 solver.cpp:136] Iteration 15, Testing net
I0829 05:08:48.169282 15446 solver.cpp:172] Test score #0: 0.594517
I0829 05:08:48.169322 15446 solver.cpp:172] Test score #1: 0.504406
I0829 05:08:49.185052 15446 solver.cpp:269] Iteration 16, lr = 5e-06
I0829 05:08:49.411061 15446 solver.cpp:117] Iteration 16, loss = 0.678784
