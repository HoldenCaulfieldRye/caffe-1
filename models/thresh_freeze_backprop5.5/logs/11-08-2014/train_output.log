nohup: ignoring input
I0811 18:57:05.591615 27382 finetune_net.cpp:25] Starting Optimization
I0811 18:57:05.591717 27382 solver.cpp:41] Creating training net.
I0811 18:57:05.592278 27382 net.cpp:75] Creating Layer data
I0811 18:57:05.592291 27382 net.cpp:111] data -> data
I0811 18:57:05.592303 27382 net.cpp:111] data -> label
I0811 18:57:05.592350 27382 data_layer.cpp:145] Opening leveldb thresh_fine_train_leveldb
I0811 18:57:13.665252 27382 data_layer.cpp:185] output data size: 128,3,227,227
I0811 18:57:13.665283 27382 data_layer.cpp:204] Loading mean file from../../data/thresh/thresh_fine_mean.binaryproto
E0811 18:57:13.683696 27382 common.cpp:31] Cannot create Cublas handle. Cublas won't be available.
E0811 18:57:13.688484 27382 common.cpp:38] Cannot create Curand generator. Curand won't be available.
I0811 18:57:13.688544 27382 net.cpp:126] Top shape: 128 3 227 227 (19787136)
I0811 18:57:13.688557 27382 net.cpp:126] Top shape: 128 1 1 1 (128)
I0811 18:57:13.688565 27382 net.cpp:157] data does not need backward computation.
I0811 18:57:13.688576 27382 net.cpp:75] Creating Layer conv1
I0811 18:57:13.688585 27382 net.cpp:85] conv1 <- data
I0811 18:57:13.688597 27382 net.cpp:111] conv1 -> conv1
I0811 18:57:13.690039 27382 net.cpp:126] Top shape: 128 96 55 55 (37171200)
I0811 18:57:13.690052 27382 net.cpp:157] conv1 does not need backward computation.
I0811 18:57:13.690060 27382 net.cpp:75] Creating Layer relu1
I0811 18:57:13.690065 27382 net.cpp:85] relu1 <- conv1
I0811 18:57:13.690070 27382 net.cpp:99] relu1 -> conv1 (in-place)
I0811 18:57:13.690078 27382 net.cpp:126] Top shape: 128 96 55 55 (37171200)
I0811 18:57:13.690083 27382 net.cpp:157] relu1 does not need backward computation.
I0811 18:57:13.690088 27382 net.cpp:75] Creating Layer pool1
I0811 18:57:13.690091 27382 net.cpp:85] pool1 <- conv1
I0811 18:57:13.690096 27382 net.cpp:111] pool1 -> pool1
I0811 18:57:13.690107 27382 net.cpp:126] Top shape: 128 96 27 27 (8957952)
I0811 18:57:13.690112 27382 net.cpp:157] pool1 does not need backward computation.
I0811 18:57:13.690119 27382 net.cpp:75] Creating Layer norm1
I0811 18:57:13.690124 27382 net.cpp:85] norm1 <- pool1
I0811 18:57:13.690129 27382 net.cpp:111] norm1 -> norm1
I0811 18:57:13.690137 27382 net.cpp:126] Top shape: 128 96 27 27 (8957952)
I0811 18:57:13.690142 27382 net.cpp:157] norm1 does not need backward computation.
I0811 18:57:13.690148 27382 net.cpp:75] Creating Layer conv2
I0811 18:57:13.690152 27382 net.cpp:85] conv2 <- norm1
I0811 18:57:13.690165 27382 net.cpp:111] conv2 -> conv2
I0811 18:57:13.702289 27382 net.cpp:126] Top shape: 128 256 27 27 (23887872)
I0811 18:57:13.702312 27382 net.cpp:157] conv2 does not need backward computation.
I0811 18:57:13.702322 27382 net.cpp:75] Creating Layer relu2
I0811 18:57:13.702327 27382 net.cpp:85] relu2 <- conv2
I0811 18:57:13.702333 27382 net.cpp:99] relu2 -> conv2 (in-place)
I0811 18:57:13.702339 27382 net.cpp:126] Top shape: 128 256 27 27 (23887872)
I0811 18:57:13.702344 27382 net.cpp:157] relu2 does not need backward computation.
I0811 18:57:13.702349 27382 net.cpp:75] Creating Layer pool2
I0811 18:57:13.702353 27382 net.cpp:85] pool2 <- conv2
I0811 18:57:13.702358 27382 net.cpp:111] pool2 -> pool2
I0811 18:57:13.702365 27382 net.cpp:126] Top shape: 128 256 13 13 (5537792)
I0811 18:57:13.702370 27382 net.cpp:157] pool2 does not need backward computation.
I0811 18:57:13.702378 27382 net.cpp:75] Creating Layer norm2
I0811 18:57:13.702381 27382 net.cpp:85] norm2 <- pool2
I0811 18:57:13.702386 27382 net.cpp:111] norm2 -> norm2
I0811 18:57:13.702393 27382 net.cpp:126] Top shape: 128 256 13 13 (5537792)
I0811 18:57:13.702396 27382 net.cpp:157] norm2 does not need backward computation.
I0811 18:57:13.702404 27382 net.cpp:75] Creating Layer conv3
I0811 18:57:13.702407 27382 net.cpp:85] conv3 <- norm2
I0811 18:57:13.702411 27382 net.cpp:111] conv3 -> conv3
I0811 18:57:13.737097 27382 net.cpp:126] Top shape: 128 384 13 13 (8306688)
I0811 18:57:13.737119 27382 net.cpp:157] conv3 does not need backward computation.
I0811 18:57:13.737128 27382 net.cpp:75] Creating Layer relu3
I0811 18:57:13.737133 27382 net.cpp:85] relu3 <- conv3
I0811 18:57:13.737139 27382 net.cpp:99] relu3 -> conv3 (in-place)
I0811 18:57:13.737144 27382 net.cpp:126] Top shape: 128 384 13 13 (8306688)
I0811 18:57:13.737149 27382 net.cpp:157] relu3 does not need backward computation.
I0811 18:57:13.737155 27382 net.cpp:75] Creating Layer conv4
I0811 18:57:13.737159 27382 net.cpp:85] conv4 <- conv3
I0811 18:57:13.737164 27382 net.cpp:111] conv4 -> conv4
I0811 18:57:13.763156 27382 net.cpp:126] Top shape: 128 384 13 13 (8306688)
I0811 18:57:13.763183 27382 net.cpp:157] conv4 does not need backward computation.
I0811 18:57:13.763191 27382 net.cpp:75] Creating Layer relu4
I0811 18:57:13.763196 27382 net.cpp:85] relu4 <- conv4
I0811 18:57:13.763205 27382 net.cpp:99] relu4 -> conv4 (in-place)
I0811 18:57:13.763211 27382 net.cpp:126] Top shape: 128 384 13 13 (8306688)
I0811 18:57:13.763214 27382 net.cpp:157] relu4 does not need backward computation.
I0811 18:57:13.763221 27382 net.cpp:75] Creating Layer conv5
I0811 18:57:13.763224 27382 net.cpp:85] conv5 <- conv4
I0811 18:57:13.763229 27382 net.cpp:111] conv5 -> conv5
I0811 18:57:13.780586 27382 net.cpp:126] Top shape: 128 256 13 13 (5537792)
I0811 18:57:13.780612 27382 net.cpp:157] conv5 does not need backward computation.
I0811 18:57:13.780621 27382 net.cpp:75] Creating Layer relu5
I0811 18:57:13.780627 27382 net.cpp:85] relu5 <- conv5
I0811 18:57:13.780633 27382 net.cpp:99] relu5 -> conv5 (in-place)
I0811 18:57:13.780638 27382 net.cpp:126] Top shape: 128 256 13 13 (5537792)
I0811 18:57:13.780642 27382 net.cpp:157] relu5 does not need backward computation.
I0811 18:57:13.780648 27382 net.cpp:75] Creating Layer pool5
I0811 18:57:13.780652 27382 net.cpp:85] pool5 <- conv5
I0811 18:57:13.780657 27382 net.cpp:111] pool5 -> pool5
I0811 18:57:13.780663 27382 net.cpp:126] Top shape: 128 256 6 6 (1179648)
I0811 18:57:13.780668 27382 net.cpp:157] pool5 does not need backward computation.
I0811 18:57:13.780676 27382 net.cpp:75] Creating Layer fc6
I0811 18:57:13.780680 27382 net.cpp:85] fc6 <- pool5
I0811 18:57:13.780685 27382 net.cpp:111] fc6 -> fc6
I0811 18:57:15.309490 27382 net.cpp:126] Top shape: 128 4096 1 1 (524288)
I0811 18:57:15.309523 27382 net.cpp:152] fc6 needs backward computation.
I0811 18:57:15.309533 27382 net.cpp:75] Creating Layer relu6
I0811 18:57:15.309538 27382 net.cpp:85] relu6 <- fc6
I0811 18:57:15.309546 27382 net.cpp:99] relu6 -> fc6 (in-place)
I0811 18:57:15.309552 27382 net.cpp:126] Top shape: 128 4096 1 1 (524288)
I0811 18:57:15.309556 27382 net.cpp:152] relu6 needs backward computation.
I0811 18:57:15.309561 27382 net.cpp:75] Creating Layer drop6
I0811 18:57:15.309566 27382 net.cpp:85] drop6 <- fc6
I0811 18:57:15.309569 27382 net.cpp:99] drop6 -> fc6 (in-place)
I0811 18:57:15.309582 27382 net.cpp:126] Top shape: 128 4096 1 1 (524288)
I0811 18:57:15.309587 27382 net.cpp:152] drop6 needs backward computation.
I0811 18:57:15.309593 27382 net.cpp:75] Creating Layer fc7
I0811 18:57:15.309597 27382 net.cpp:85] fc7 <- fc6
I0811 18:57:15.309607 27382 net.cpp:111] fc7 -> fc7
I0811 18:57:15.962872 27382 net.cpp:126] Top shape: 128 4096 1 1 (524288)
I0811 18:57:15.962901 27382 net.cpp:152] fc7 needs backward computation.
I0811 18:57:15.962910 27382 net.cpp:75] Creating Layer relu7
I0811 18:57:15.962916 27382 net.cpp:85] relu7 <- fc7
I0811 18:57:15.962924 27382 net.cpp:99] relu7 -> fc7 (in-place)
I0811 18:57:15.962929 27382 net.cpp:126] Top shape: 128 4096 1 1 (524288)
I0811 18:57:15.962934 27382 net.cpp:152] relu7 needs backward computation.
I0811 18:57:15.962939 27382 net.cpp:75] Creating Layer drop7
I0811 18:57:15.962942 27382 net.cpp:85] drop7 <- fc7
I0811 18:57:15.962946 27382 net.cpp:99] drop7 -> fc7 (in-place)
I0811 18:57:15.962951 27382 net.cpp:126] Top shape: 128 4096 1 1 (524288)
I0811 18:57:15.962956 27382 net.cpp:152] drop7 needs backward computation.
I0811 18:57:15.962962 27382 net.cpp:75] Creating Layer fc8_clamp
I0811 18:57:15.962965 27382 net.cpp:85] fc8_clamp <- fc7
I0811 18:57:15.962970 27382 net.cpp:111] fc8_clamp -> fc8_aero
I0811 18:57:15.963312 27382 net.cpp:126] Top shape: 128 2 1 1 (256)
I0811 18:57:15.963320 27382 net.cpp:152] fc8_clamp needs backward computation.
I0811 18:57:15.963331 27382 net.cpp:75] Creating Layer threshold
I0811 18:57:15.963336 27382 net.cpp:85] threshold <- fc8_aero
I0811 18:57:15.963341 27382 net.cpp:85] threshold <- label
I0811 18:57:15.963346 27382 net.cpp:111] threshold -> fc8_aero_thresh
I0811 18:57:15.963352 27382 net.cpp:99] threshold -> label (in-place)
I0811 18:57:15.963359 27382 net.cpp:126] Top shape: 128 2 1 1 (256)
I0811 18:57:15.963364 27382 net.cpp:126] Top shape: 128 1 1 1 (128)
I0811 18:57:15.963368 27382 net.cpp:152] threshold needs backward computation.
I0811 18:57:15.963374 27382 net.cpp:75] Creating Layer loss
I0811 18:57:15.963378 27382 net.cpp:85] loss <- fc8_aero_thresh
I0811 18:57:15.963383 27382 net.cpp:85] loss <- label
I0811 18:57:15.963392 27382 net.cpp:152] loss needs backward computation.
I0811 18:57:15.963423 27382 net.cpp:181] Collecting Learning Rate and Weight Decay.
I0811 18:57:15.963435 27382 net.cpp:174] Network initialization done.
I0811 18:57:15.963439 27382 net.cpp:175] Memory required for Data 536869888
I0811 18:57:15.963485 27382 solver.cpp:44] Creating testing net.
I0811 18:57:15.964181 27382 net.cpp:75] Creating Layer data
I0811 18:57:15.964193 27382 net.cpp:111] data -> data
I0811 18:57:15.964201 27382 net.cpp:111] data -> label
I0811 18:57:15.964208 27382 data_layer.cpp:145] Opening leveldb thresh_fine_val_leveldb
I0811 18:57:18.671229 27382 data_layer.cpp:185] output data size: 512,3,227,227
I0811 18:57:18.671255 27382 data_layer.cpp:204] Loading mean file from../../data/thresh/thresh_fine_mean.binaryproto
I0811 18:57:18.826700 27382 net.cpp:126] Top shape: 512 3 227 227 (79148544)
I0811 18:57:18.826726 27382 net.cpp:126] Top shape: 512 1 1 1 (512)
I0811 18:57:18.826733 27382 net.cpp:157] data does not need backward computation.
I0811 18:57:18.826747 27382 net.cpp:75] Creating Layer conv1
I0811 18:57:18.826753 27382 net.cpp:85] conv1 <- data
I0811 18:57:18.826761 27382 net.cpp:111] conv1 -> conv1
I0811 18:57:18.828142 27382 net.cpp:126] Top shape: 512 96 55 55 (148684800)
I0811 18:57:18.828152 27382 net.cpp:152] conv1 needs backward computation.
I0811 18:57:18.828160 27382 net.cpp:75] Creating Layer relu1
I0811 18:57:18.828163 27382 net.cpp:85] relu1 <- conv1
I0811 18:57:18.828168 27382 net.cpp:99] relu1 -> conv1 (in-place)
I0811 18:57:18.828173 27382 net.cpp:126] Top shape: 512 96 55 55 (148684800)
I0811 18:57:18.828177 27382 net.cpp:152] relu1 needs backward computation.
I0811 18:57:18.828183 27382 net.cpp:75] Creating Layer pool1
I0811 18:57:18.828187 27382 net.cpp:85] pool1 <- conv1
I0811 18:57:18.828191 27382 net.cpp:111] pool1 -> pool1
I0811 18:57:18.828197 27382 net.cpp:126] Top shape: 512 96 27 27 (35831808)
I0811 18:57:18.828202 27382 net.cpp:152] pool1 needs backward computation.
I0811 18:57:18.828208 27382 net.cpp:75] Creating Layer norm1
I0811 18:57:18.828212 27382 net.cpp:85] norm1 <- pool1
I0811 18:57:18.828217 27382 net.cpp:111] norm1 -> norm1
I0811 18:57:18.828224 27382 net.cpp:126] Top shape: 512 96 27 27 (35831808)
I0811 18:57:18.828229 27382 net.cpp:152] norm1 needs backward computation.
I0811 18:57:18.828235 27382 net.cpp:75] Creating Layer conv2
I0811 18:57:18.828239 27382 net.cpp:85] conv2 <- norm1
I0811 18:57:18.828243 27382 net.cpp:111] conv2 -> conv2
I0811 18:57:18.840235 27382 net.cpp:126] Top shape: 512 256 27 27 (95551488)
I0811 18:57:18.840263 27382 net.cpp:152] conv2 needs backward computation.
I0811 18:57:18.840271 27382 net.cpp:75] Creating Layer relu2
I0811 18:57:18.840276 27382 net.cpp:85] relu2 <- conv2
I0811 18:57:18.840282 27382 net.cpp:99] relu2 -> conv2 (in-place)
I0811 18:57:18.840288 27382 net.cpp:126] Top shape: 512 256 27 27 (95551488)
I0811 18:57:18.840292 27382 net.cpp:152] relu2 needs backward computation.
I0811 18:57:18.840297 27382 net.cpp:75] Creating Layer pool2
I0811 18:57:18.840301 27382 net.cpp:85] pool2 <- conv2
I0811 18:57:18.840306 27382 net.cpp:111] pool2 -> pool2
I0811 18:57:18.840313 27382 net.cpp:126] Top shape: 512 256 13 13 (22151168)
I0811 18:57:18.840317 27382 net.cpp:152] pool2 needs backward computation.
I0811 18:57:18.840324 27382 net.cpp:75] Creating Layer norm2
I0811 18:57:18.840327 27382 net.cpp:85] norm2 <- pool2
I0811 18:57:18.840332 27382 net.cpp:111] norm2 -> norm2
I0811 18:57:18.840338 27382 net.cpp:126] Top shape: 512 256 13 13 (22151168)
I0811 18:57:18.840342 27382 net.cpp:152] norm2 needs backward computation.
I0811 18:57:18.840348 27382 net.cpp:75] Creating Layer conv3
I0811 18:57:18.840353 27382 net.cpp:85] conv3 <- norm2
I0811 18:57:18.840358 27382 net.cpp:111] conv3 -> conv3
I0811 18:57:18.874897 27382 net.cpp:126] Top shape: 512 384 13 13 (33226752)
I0811 18:57:18.874923 27382 net.cpp:152] conv3 needs backward computation.
I0811 18:57:18.874933 27382 net.cpp:75] Creating Layer relu3
I0811 18:57:18.874938 27382 net.cpp:85] relu3 <- conv3
I0811 18:57:18.874944 27382 net.cpp:99] relu3 -> conv3 (in-place)
I0811 18:57:18.874949 27382 net.cpp:126] Top shape: 512 384 13 13 (33226752)
I0811 18:57:18.874953 27382 net.cpp:152] relu3 needs backward computation.
I0811 18:57:18.874960 27382 net.cpp:75] Creating Layer conv4
I0811 18:57:18.874964 27382 net.cpp:85] conv4 <- conv3
I0811 18:57:18.874969 27382 net.cpp:111] conv4 -> conv4
I0811 18:57:18.901006 27382 net.cpp:126] Top shape: 512 384 13 13 (33226752)
I0811 18:57:18.901034 27382 net.cpp:152] conv4 needs backward computation.
I0811 18:57:18.901043 27382 net.cpp:75] Creating Layer relu4
I0811 18:57:18.901048 27382 net.cpp:85] relu4 <- conv4
I0811 18:57:18.901056 27382 net.cpp:99] relu4 -> conv4 (in-place)
I0811 18:57:18.901060 27382 net.cpp:126] Top shape: 512 384 13 13 (33226752)
I0811 18:57:18.901064 27382 net.cpp:152] relu4 needs backward computation.
I0811 18:57:18.901070 27382 net.cpp:75] Creating Layer conv5
I0811 18:57:18.901074 27382 net.cpp:85] conv5 <- conv4
I0811 18:57:18.901078 27382 net.cpp:111] conv5 -> conv5
I0811 18:57:18.918409 27382 net.cpp:126] Top shape: 512 256 13 13 (22151168)
I0811 18:57:18.918436 27382 net.cpp:152] conv5 needs backward computation.
I0811 18:57:18.918444 27382 net.cpp:75] Creating Layer relu5
I0811 18:57:18.918449 27382 net.cpp:85] relu5 <- conv5
I0811 18:57:18.918457 27382 net.cpp:99] relu5 -> conv5 (in-place)
I0811 18:57:18.918462 27382 net.cpp:126] Top shape: 512 256 13 13 (22151168)
I0811 18:57:18.918465 27382 net.cpp:152] relu5 needs backward computation.
I0811 18:57:18.918472 27382 net.cpp:75] Creating Layer pool5
I0811 18:57:18.918475 27382 net.cpp:85] pool5 <- conv5
I0811 18:57:18.918479 27382 net.cpp:111] pool5 -> pool5
I0811 18:57:18.918488 27382 net.cpp:126] Top shape: 512 256 6 6 (4718592)
I0811 18:57:18.918491 27382 net.cpp:152] pool5 needs backward computation.
I0811 18:57:18.918500 27382 net.cpp:75] Creating Layer fc6
I0811 18:57:18.918504 27382 net.cpp:85] fc6 <- pool5
I0811 18:57:18.918509 27382 net.cpp:111] fc6 -> fc6
I0811 18:57:20.449306 27382 net.cpp:126] Top shape: 512 4096 1 1 (2097152)
I0811 18:57:20.449340 27382 net.cpp:152] fc6 needs backward computation.
I0811 18:57:20.449350 27382 net.cpp:75] Creating Layer relu6
I0811 18:57:20.449357 27382 net.cpp:85] relu6 <- fc6
I0811 18:57:20.449363 27382 net.cpp:99] relu6 -> fc6 (in-place)
I0811 18:57:20.449369 27382 net.cpp:126] Top shape: 512 4096 1 1 (2097152)
I0811 18:57:20.449373 27382 net.cpp:152] relu6 needs backward computation.
I0811 18:57:20.449378 27382 net.cpp:75] Creating Layer drop6
I0811 18:57:20.449383 27382 net.cpp:85] drop6 <- fc6
I0811 18:57:20.449386 27382 net.cpp:99] drop6 -> fc6 (in-place)
I0811 18:57:20.449393 27382 net.cpp:126] Top shape: 512 4096 1 1 (2097152)
I0811 18:57:20.449396 27382 net.cpp:152] drop6 needs backward computation.
I0811 18:57:20.449403 27382 net.cpp:75] Creating Layer fc7
I0811 18:57:20.449405 27382 net.cpp:85] fc7 <- fc6
I0811 18:57:20.449410 27382 net.cpp:111] fc7 -> fc7
I0811 18:57:21.128841 27382 net.cpp:126] Top shape: 512 4096 1 1 (2097152)
I0811 18:57:21.128868 27382 net.cpp:152] fc7 needs backward computation.
I0811 18:57:21.128878 27382 net.cpp:75] Creating Layer relu7
I0811 18:57:21.128885 27382 net.cpp:85] relu7 <- fc7
I0811 18:57:21.128891 27382 net.cpp:99] relu7 -> fc7 (in-place)
I0811 18:57:21.128896 27382 net.cpp:126] Top shape: 512 4096 1 1 (2097152)
I0811 18:57:21.128906 27382 net.cpp:152] relu7 needs backward computation.
I0811 18:57:21.128912 27382 net.cpp:75] Creating Layer drop7
I0811 18:57:21.128916 27382 net.cpp:85] drop7 <- fc7
I0811 18:57:21.128921 27382 net.cpp:99] drop7 -> fc7 (in-place)
I0811 18:57:21.128926 27382 net.cpp:126] Top shape: 512 4096 1 1 (2097152)
I0811 18:57:21.128931 27382 net.cpp:152] drop7 needs backward computation.
I0811 18:57:21.128937 27382 net.cpp:75] Creating Layer fc8_clamp
I0811 18:57:21.128939 27382 net.cpp:85] fc8_clamp <- fc7
I0811 18:57:21.128944 27382 net.cpp:111] fc8_clamp -> fc8_aero
I0811 18:57:21.129276 27382 net.cpp:126] Top shape: 512 2 1 1 (1024)
I0811 18:57:21.129283 27382 net.cpp:152] fc8_clamp needs backward computation.
I0811 18:57:21.129289 27382 net.cpp:75] Creating Layer threshold
I0811 18:57:21.129293 27382 net.cpp:85] threshold <- fc8_aero
I0811 18:57:21.129298 27382 net.cpp:85] threshold <- label
I0811 18:57:21.129303 27382 net.cpp:111] threshold -> fc8_aero_thresh
I0811 18:57:21.129309 27382 net.cpp:99] threshold -> label (in-place)
I0811 18:57:21.129317 27382 net.cpp:126] Top shape: 512 2 1 1 (1024)
I0811 18:57:21.129320 27382 net.cpp:126] Top shape: 512 1 1 1 (512)
I0811 18:57:21.129324 27382 net.cpp:152] threshold needs backward computation.
I0811 18:57:21.129329 27382 net.cpp:75] Creating Layer prob
I0811 18:57:21.129333 27382 net.cpp:85] prob <- fc8_aero_thresh
I0811 18:57:21.129338 27382 net.cpp:111] prob -> prob
I0811 18:57:21.129346 27382 net.cpp:126] Top shape: 512 2 1 1 (1024)
I0811 18:57:21.129351 27382 net.cpp:152] prob needs backward computation.
I0811 18:57:21.129355 27382 net.cpp:75] Creating Layer accuracy
I0811 18:57:21.129359 27382 net.cpp:85] accuracy <- prob
I0811 18:57:21.129364 27382 net.cpp:85] accuracy <- label
I0811 18:57:21.129369 27382 net.cpp:111] accuracy -> accuracy
I0811 18:57:21.129380 27382 net.cpp:126] Top shape: 1 2 1 1 (2)
I0811 18:57:21.129385 27382 net.cpp:152] accuracy needs backward computation.
I0811 18:57:21.129389 27382 net.cpp:163] This network produces output accuracy
I0811 18:57:21.129408 27382 net.cpp:181] Collecting Learning Rate and Weight Decay.
I0811 18:57:21.129420 27382 net.cpp:174] Network initialization done.
I0811 18:57:21.129423 27382 net.cpp:175] Memory required for Data 2147483656
I0811 18:57:21.129462 27382 solver.cpp:49] Solver scaffolding done.
I0811 18:57:21.129469 27382 finetune_net.cpp:27] Loading from ../alexnet/caffe_alexnet_model
I0811 18:57:22.701786 27382 net.cpp:319] Copying source layer data
I0811 18:57:22.701830 27382 net.cpp:319] Copying source layer conv1
I0811 18:57:22.701946 27382 net.cpp:319] Copying source layer relu1
I0811 18:57:22.701958 27382 net.cpp:319] Copying source layer norm1
I0811 18:57:22.701966 27382 net.cpp:319] Copying source layer pool1
I0811 18:57:22.701973 27382 net.cpp:319] Copying source layer conv2
I0811 18:57:22.702747 27382 net.cpp:319] Copying source layer relu2
I0811 18:57:22.702769 27382 net.cpp:319] Copying source layer norm2
I0811 18:57:22.702777 27382 net.cpp:319] Copying source layer pool2
I0811 18:57:22.702788 27382 net.cpp:319] Copying source layer conv3
I0811 18:57:22.705098 27382 net.cpp:319] Copying source layer relu3
I0811 18:57:22.705121 27382 net.cpp:319] Copying source layer conv4
I0811 18:57:22.706826 27382 net.cpp:319] Copying source layer relu4
I0811 18:57:22.706842 27382 net.cpp:319] Copying source layer conv5
I0811 18:57:22.707983 27382 net.cpp:319] Copying source layer relu5
I0811 18:57:22.708000 27382 net.cpp:319] Copying source layer pool5
I0811 18:57:22.708009 27382 net.cpp:319] Copying source layer fc6
I0811 18:57:22.828446 27382 net.cpp:319] Copying source layer relu6
I0811 18:57:22.828482 27382 net.cpp:319] Copying source layer drop6
I0811 18:57:22.828487 27382 net.cpp:319] Copying source layer fc7
I0811 18:57:22.851425 27382 net.cpp:319] Copying source layer relu7
I0811 18:57:22.851455 27382 net.cpp:319] Copying source layer drop7
I0811 18:57:22.851459 27382 net.cpp:316] Ignoring source layer fc8
I0811 18:57:22.851464 27382 net.cpp:319] Copying source layer loss
I0811 18:57:22.865128 27382 solver.cpp:61] Solving threshFineNet
I0811 18:57:22.865156 27382 solver.cpp:106] Iteration 0, Testing net
F0811 18:57:22.883492 27382 syncedmem.cpp:47] Check failed: error == cudaSuccess (30 vs. 0)  unknown error
*** Check failure stack trace: ***
    @     0x7fd493732f9d  google::LogMessage::Fail()
    @     0x7fd4937350af  google::LogMessage::SendToLog()
    @     0x7fd493732b8c  google::LogMessage::Flush()
    @     0x7fd49373594d  google::LogMessageFatal::~LogMessageFatal()
    @           0x4ba497  caffe::SyncedMemory::mutable_gpu_data()
    @           0x45f9c1  caffe::Blob<>::mutable_gpu_data()
    @           0x4c1a17  caffe::DataLayer<>::Forward_gpu()
    @           0x4385c0  caffe::Net<>::ForwardPrefilled()
    @           0x446511  caffe::Solver<>::Test()
    @           0x448623  caffe::Solver<>::Solve()
    @           0x412846  main
    @     0x7fd4912caea5  (unknown)
    @           0x4145f9  (unknown)
Aborted
Done.
